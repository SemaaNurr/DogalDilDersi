{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "349f643c-7e1b-479a-bbac-9dd9a46dad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d38c7446-8739-431d-8bd9-adc6391cb9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breakfast for the lazy</td>\n",
       "      <td>Put cottage cheese in a wide bowl, add an egg,...</td>\n",
       "      <td>Chicken egg: 1 piece, soft cottage cheese: 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breek breakfast</td>\n",
       "      <td>Rinse buckwheat, pour 2 cups of boiling water,...</td>\n",
       "      <td>Buckwheat cereal: 1 cup, chopped parsley: to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Childhood breakfast</td>\n",
       "      <td>Grate the carrots and green apple on the middl...</td>\n",
       "      <td>Carrots: 1 piece, apple: 1 piece, oranges: 1 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French croutons for breakfast</td>\n",
       "      <td>Mix the egg with milk.Salt.Dip the pieces of t...</td>\n",
       "      <td>Baton: 3 pieces, milk: 2 tablespoons, chicken ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low -calorie breakfast</td>\n",
       "      <td>Boil the egg boiled.Cut the cheese and tomatoe...</td>\n",
       "      <td>Green salad: 0.1 bundles, chicken eggs: 1 piec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0         Breakfast for the lazy   \n",
       "1                Breek breakfast   \n",
       "2            Childhood breakfast   \n",
       "3  French croutons for breakfast   \n",
       "4         Low -calorie breakfast   \n",
       "\n",
       "                                                text  \\\n",
       "0  Put cottage cheese in a wide bowl, add an egg,...   \n",
       "1  Rinse buckwheat, pour 2 cups of boiling water,...   \n",
       "2  Grate the carrots and green apple on the middl...   \n",
       "3  Mix the egg with milk.Salt.Dip the pieces of t...   \n",
       "4  Boil the egg boiled.Cut the cheese and tomatoe...   \n",
       "\n",
       "                                          ingredient  \n",
       "0  Chicken egg: 1 piece, soft cottage cheese: 200...  \n",
       "1  Buckwheat cereal: 1 cup, chopped parsley: to t...  \n",
       "2  Carrots: 1 piece, apple: 1 piece, oranges: 1 p...  \n",
       "3  Baton: 3 pieces, milk: 2 tablespoons, chicken ...  \n",
       "4  Green salad: 0.1 bundles, chicken eggs: 1 piec...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV dosyasını yükleyin\n",
    "df = pd.read_csv('food.csv', encoding='utf-8')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d7f81b-0e73-4907-a565-e4ba1810ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name_sentences  \\\n",
      "0  [Breakfast for the lazy]   \n",
      "1         [Breek breakfast]   \n",
      "2     [Childhood breakfast]   \n",
      "\n",
      "                                      text_sentences  \\\n",
      "0  [Put cottage cheese in a wide bowl, add an egg...   \n",
      "1  [Rinse buckwheat, pour 2 cups of boiling water...   \n",
      "2  [Grate the carrots and green apple on the midd...   \n",
      "\n",
      "                                ingredient_sentences  \n",
      "0  [Chicken egg: 1 piece, soft cottage cheese: 20...  \n",
      "1  [Buckwheat cereal: 1 cup, chopped parsley: to ...  \n",
      "2  [Carrots: 1 piece, apple: 1 piece, oranges: 1 ...  \n"
     ]
    }
   ],
   "source": [
    "# Tüm sütunlarda cümlelere ayırma\n",
    "df['name_sentences'] = df['name'].apply(sent_tokenize)\n",
    "df['text_sentences'] = df['text'].apply(sent_tokenize)\n",
    "df['ingredient_sentences'] = df['ingredient'].apply(sent_tokenize)\n",
    "\n",
    "# İlk 3 satırı kontrol edelim\n",
    "print(df[['name_sentences', 'text_sentences', 'ingredient_sentences']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b562dff9-58c7-4bdc-b110-b740cc24cae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name  \\\n",
      "0             breakfast lazy   \n",
      "1            breek breakfast   \n",
      "2        childhood breakfast   \n",
      "3  french croutons breakfast   \n",
      "4              low breakfast   \n",
      "\n",
      "                                                text  \\\n",
      "0  put cottage cheese wide bowl add egg sugar flo...   \n",
      "1  rinse buckwheat pour cups boiling water salt c...   \n",
      "2  grate carrots green apple middle zest juice ha...   \n",
      "3  mix egg pieces loaf egg mixture vegetable oil ...   \n",
      "4                              boil egg cheese taste   \n",
      "\n",
      "                                          ingredient  \n",
      "0  chicken egg piece soft cottage cheese g wheat ...  \n",
      "1  buckwheat cereal cup chopped parsley taste cho...  \n",
      "2  carrots piece apple piece oranges piece raisin...  \n",
      "3  baton pieces milk tablespoons chicken egg piec...  \n",
      "4  green salad bundles chicken eggs piece tomatoe...  \n"
     ]
    }
   ],
   "source": [
    "# Stopwords ve noktalama temizliği için hazırlık\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# Metin temizleme fonksiyonu\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        tokens = [word.translate(table) for word in tokens if word.isalpha()]\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    except:\n",
    "        return text  # hata durumunda orijinal metni döndür\n",
    "\n",
    "# Temizlenecek sütunlar\n",
    "target_columns = ['text', 'ingredient', 'name']\n",
    "\n",
    "# Yalnızca bu sütunlara temizleme işlemini uygula\n",
    "for col in target_columns:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "\n",
    "# İlk 5 satırı kontrol et\n",
    "print(df[['name', 'text', 'ingredient']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "146d248f-c773-4a7b-970b-5e04232a73d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     text_lemmatized  \\\n",
      "0  put cottage cheese wide bowl add egg sugar flo...   \n",
      "1  rinse buckwheat pour cup boiling water salt co...   \n",
      "2  grate carrot green apple middle zest juice hal...   \n",
      "3  mix egg piece loaf egg mixture vegetable oil side   \n",
      "4                              boil egg cheese taste   \n",
      "\n",
      "                               ingredient_lemmatized  \\\n",
      "0  chicken egg piece soft cottage cheese g wheat ...   \n",
      "1  buckwheat cereal cup chopped parsley taste cho...   \n",
      "2  carrot piece apple piece orange piece raisin g...   \n",
      "3  baton piece milk tablespoon chicken egg piece ...   \n",
      "4  green salad bundle chicken egg piece tomato pi...   \n",
      "\n",
      "            name_lemmatized  \\\n",
      "0            breakfast lazy   \n",
      "1           breek breakfast   \n",
      "2       childhood breakfast   \n",
      "3  french crouton breakfast   \n",
      "4             low breakfast   \n",
      "\n",
      "                                        text_stemmed  \\\n",
      "0  put cottag chees wide bowl add egg sugar flour...   \n",
      "1  rins buckwheat pour cup boil water salt cover ...   \n",
      "2  grate carrot green appl middl zest juic halv c...   \n",
      "3        mix egg piec loaf egg mixtur veget oil side   \n",
      "4                                boil egg chees tast   \n",
      "\n",
      "                                  ingredient_stemmed              name_stemmed  \n",
      "0  chicken egg piec soft cottag chees g wheat flo...            breakfast lazi  \n",
      "1  buckwheat cereal cup chop parsley tast chop ci...           breek breakfast  \n",
      "2  carrot piec appl piec orang piec raisin g hone...       childhood breakfast  \n",
      "3  baton piec milk tablespoon chicken egg piec sa...  french crouton breakfast  \n",
      "4  green salad bundl chicken egg piec tomato piec...             low breakfast  \n"
     ]
    }
   ],
   "source": [
    "# Lemmatizer ve Stemmer'ı başlat\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Lemmatization fonksiyonu\n",
    "def lemmatize_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        lemmatized = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha()]\n",
    "        return ' '.join(lemmatized)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Stemming fonksiyonu\n",
    "def stem_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        stemmed = [stemmer.stem(word) for word in tokens if word.isalpha()]\n",
    "        return ' '.join(stemmed)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Hedef sütunlar\n",
    "target_columns = ['text', 'ingredient', 'name']\n",
    "\n",
    "# Her sütun için lemmatization ve stemming uygula\n",
    "for col in target_columns:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        df[f'{col}_lemmatized'] = df[col].apply(lemmatize_text)\n",
    "        df[f'{col}_stemmed'] = df[col].apply(stem_text)\n",
    "\n",
    "# İlk 5 satırı yazdır\n",
    "print(df[[f'{col}_lemmatized' for col in target_columns] +\n",
    "         [f'{col}_stemmed' for col in target_columns]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "501c387c-92c8-4313-9419-275e17bbeabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name_lemmatized_tokens  \\\n",
      "0             [breakfast, lazy]   \n",
      "1            [breek, breakfast]   \n",
      "2        [childhood, breakfast]   \n",
      "3  [french, crouton, breakfast]   \n",
      "4              [low, breakfast]   \n",
      "\n",
      "                              text_lemmatized_tokens  \\\n",
      "0  [put, cottage, cheese, wide, bowl, add, egg, s...   \n",
      "1  [rinse, buckwheat, pour, cup, boiling, water, ...   \n",
      "2  [grate, carrot, green, apple, middle, zest, ju...   \n",
      "3  [mix, egg, piece, loaf, egg, mixture, vegetabl...   \n",
      "4                         [boil, egg, cheese, taste]   \n",
      "\n",
      "                        ingredient_lemmatized_tokens  \\\n",
      "0  [chicken, egg, piece, soft, cottage, cheese, g...   \n",
      "1  [buckwheat, cereal, cup, chopped, parsley, tas...   \n",
      "2  [carrot, piece, apple, piece, orange, piece, r...   \n",
      "3  [baton, piece, milk, tablespoon, chicken, egg,...   \n",
      "4  [green, salad, bundle, chicken, egg, piece, to...   \n",
      "\n",
      "            name_stemmed_tokens  \\\n",
      "0             [breakfast, lazi]   \n",
      "1            [breek, breakfast]   \n",
      "2        [childhood, breakfast]   \n",
      "3  [french, crouton, breakfast]   \n",
      "4              [low, breakfast]   \n",
      "\n",
      "                                 text_stemmed_tokens  \\\n",
      "0  [put, cottag, chees, wide, bowl, add, egg, sug...   \n",
      "1  [rins, buckwheat, pour, cup, boil, water, salt...   \n",
      "2  [grate, carrot, green, appl, middl, zest, juic...   \n",
      "3  [mix, egg, piec, loaf, egg, mixtur, veget, oil...   \n",
      "4                           [boil, egg, chees, tast]   \n",
      "\n",
      "                           ingredient_stemmed_tokens  \n",
      "0  [chicken, egg, piec, soft, cottag, chees, g, w...  \n",
      "1  [buckwheat, cereal, cup, chop, parsley, tast, ...  \n",
      "2  [carrot, piec, appl, piec, orang, piec, raisin...  \n",
      "3  [baton, piec, milk, tablespoon, chicken, egg, ...  \n",
      "4  [green, salad, bundl, chicken, egg, piec, toma...  \n"
     ]
    }
   ],
   "source": [
    "# Hedef sütunlar\n",
    "target_columns = ['name', 'text', 'ingredient']\n",
    "\n",
    "for col in target_columns:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        # Her satıra fonksiyonu uygula, sonuç tuple (lemmatized, stemmed)\n",
    "        # İlk eleman lemmatized token listesi, ikinci eleman stemmed token listesi\n",
    "        df[f'{col}_lemmatized_tokens'] = df[col].apply(lambda x: preprocess_sentence(str(x))[0])\n",
    "        df[f'{col}_stemmed_tokens'] = df[col].apply(lambda x: preprocess_sentence(str(x))[1])\n",
    "\n",
    "# İlk 5 satırı gösterelim\n",
    "print(df[[f'{col}_lemmatized_tokens' for col in target_columns] + [f'{col}_stemmed_tokens' for col in target_columns]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b3b004-c65a-4e19-993d-f8389bf9ea3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['put', 'cottage', 'cheese', 'wide', 'bowl', 'add', 'egg', 'sugar', 'flour', 'fork', 'mix', 'homogeneous', 'mass', 'turned', 'sticky', 'add', 'flour', 'half', 'table', 'small', 'amount', 'flour', 'lay', 'cottage', 'two', 'equal', 'part', 'roll', 'sausage', 'thickness', 'sausage', 'small', 'identical', 'piece', 'sharp', 'desired', 'slightly', 'add', 'piece', 'give', 'rounded', 'small', 'pan', 'bring', 'water', 'lower', 'dumpling', 'boiling', 'water', 'one', 'stirring', 'slightly', 'slotted', 'spoon', 'dumpling', 'come', 'surface', 'plus', 'another', 'finished', 'dumpling', 'pan', 'plate', 'pour', 'jam', 'example', 'serve', 'hot', 'warm'], ['rinse', 'buckwheat', 'pour', 'cup', 'boiling', 'water', 'salt', 'cover', 'cover', 'minute', 'buckwheat', 'eaten', 'lose', 'nutritional', 'better', 'required', 'amount', 'wounded', 'buckwheat', 'portioned', 'plate', 'seasoned', 'olive', 'oil', 'soy', 'sauce', 'lemon', 'juice', 'chopped', 'lemon', 'chopped', 'green', 'chopped', 'vegetable', 'bulgarian', 'pepper', 'carrot', 'pumpkin', 'radish', 'green', 'cocktail'], ['grate', 'carrot', 'green', 'apple', 'middle', 'zest', 'juice', 'halve', 'cut', 'second', 'small', 'apple', 'carrot', 'orange', 'raisin', 'nut', 'favorite', 'season', 'juice', 'honey', 'add', 'cinnamon']]\n",
      "[['put', 'cottag', 'chees', 'wide', 'bowl', 'add', 'egg', 'sugar', 'flour', 'fork', 'mix', 'homogen', 'mass', 'turn', 'sticki', 'add', 'flour', 'half', 'tabl', 'small', 'amount', 'flour', 'lay', 'cottag', 'two', 'equal', 'part', 'roll', 'sausag', 'thick', 'sausag', 'small', 'ident', 'piec', 'sharp', 'desir', 'slightli', 'add', 'piec', 'give', 'round', 'small', 'pan', 'bring', 'water', 'lower', 'dumpl', 'boil', 'water', 'one', 'stir', 'slightli', 'slot', 'spoon', 'dumpl', 'come', 'surfac', 'plu', 'anoth', 'finish', 'dumpl', 'pan', 'plate', 'pour', 'jam', 'exampl', 'serv', 'hot', 'warm'], ['rins', 'buckwheat', 'pour', 'cup', 'boil', 'water', 'salt', 'cover', 'cover', 'minut', 'buckwheat', 'eaten', 'lose', 'nutrit', 'better', 'requir', 'amount', 'wound', 'buckwheat', 'portion', 'plate', 'season', 'oliv', 'oil', 'soy', 'sauc', 'lemon', 'juic', 'chop', 'lemon', 'chop', 'green', 'chop', 'veget', 'bulgarian', 'pepper', 'carrot', 'pumpkin', 'radish', 'green', 'cocktail'], ['grate', 'carrot', 'green', 'appl', 'middl', 'zest', 'juic', 'halv', 'cut', 'second', 'small', 'appl', 'carrot', 'orang', 'raisin', 'nut', 'favorit', 'season', 'juic', 'honey', 'add', 'cinnamon']]\n"
     ]
    }
   ],
   "source": [
    "# Örnek metin listesini cümle cümle işleyecek fonksiyon\n",
    "def preprocess_corpus(corpus):\n",
    "    tokenized_corpus_lemmatized = []\n",
    "    tokenized_corpus_stemmed = []\n",
    "\n",
    "    for text in corpus:\n",
    "        sentences = sent_tokenize(text)  # Metni cümlelere böl\n",
    "        for sentence in sentences:\n",
    "            tokens = word_tokenize(sentence)\n",
    "            filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "            \n",
    "            lemmatized = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "            stemmed = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "            tokenized_corpus_lemmatized.append(lemmatized)\n",
    "            tokenized_corpus_stemmed.append(stemmed)\n",
    "\n",
    "    return tokenized_corpus_lemmatized, tokenized_corpus_stemmed\n",
    "\n",
    "# Örnek kullanım:\n",
    "texts = df['text'].dropna().tolist()  # Örnek olarak 'text' sütununu alıyoruz\n",
    "lem, stem = preprocess_corpus(texts)\n",
    "\n",
    "print(lem[:3])\n",
    "print(stem[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d886625-f4f2-47e1-9e97-2a87203520d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name_lemmatized_sentences  \\\n",
      "0       [[breakfast, lazy]]   \n",
      "1      [[breek, breakfast]]   \n",
      "2  [[childhood, breakfast]]   \n",
      "\n",
      "                           text_lemmatized_sentences  \\\n",
      "0  [[put, cottage, cheese, wide, bowl, add, egg, ...   \n",
      "1  [[rinse, buckwheat, pour, cup, boiling, water,...   \n",
      "2  [[grate, carrot, green, apple, middle, zest, j...   \n",
      "\n",
      "                     ingredient_lemmatized_sentences  \\\n",
      "0  [[chicken, egg, piece, soft, cottage, cheese, ...   \n",
      "1  [[buckwheat, cereal, cup, chopped, parsley, ta...   \n",
      "2  [[carrot, piece, apple, piece, orange, piece, ...   \n",
      "\n",
      "     name_stemmed_sentences  \\\n",
      "0       [[breakfast, lazi]]   \n",
      "1      [[breek, breakfast]]   \n",
      "2  [[childhood, breakfast]]   \n",
      "\n",
      "                              text_stemmed_sentences  \\\n",
      "0  [[put, cottag, chees, wide, bowl, add, egg, su...   \n",
      "1  [[rins, buckwheat, pour, cup, boil, water, sal...   \n",
      "2  [[grate, carrot, green, appl, middl, zest, jui...   \n",
      "\n",
      "                        ingredient_stemmed_sentences  \n",
      "0  [[chicken, egg, piec, soft, cottag, chees, g, ...  \n",
      "1  [[buckwheat, cereal, cup, chop, parsley, tast,...  \n",
      "2  [[carrot, piec, appl, piec, orang, piec, raisi...  \n"
     ]
    }
   ],
   "source": [
    "# Önce gerekli kütüphaneler ve fonksiyonun tanımı olmalı (daha önce verdiğin preprocess_sentence burada kullanılacak)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Boş sütunlar için hazırlık\n",
    "for col in target_columns:\n",
    "    df[f'{col}_lemmatized_sentences'] = [[] for _ in range(len(df))]\n",
    "    df[f'{col}_stemmed_sentences'] = [[] for _ in range(len(df))]\n",
    "\n",
    "for col in target_columns:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        for idx, text in df[col].items():\n",
    "            sentences = sent_tokenize(str(text))  # Satırdaki metni cümlelere ayır\n",
    "            lemmatized_sentences = []\n",
    "            stemmed_sentences = []\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
    "                lemmatized_sentences.append(lemmatized_tokens)\n",
    "                stemmed_sentences.append(stemmed_tokens)\n",
    "            \n",
    "            df.at[idx, f'{col}_lemmatized_sentences'] = lemmatized_sentences\n",
    "            df.at[idx, f'{col}_stemmed_sentences'] = stemmed_sentences\n",
    "\n",
    "# Örnek çıktı kontrolü\n",
    "print(df[[f'{col}_lemmatized_sentences' for col in target_columns] + [f'{col}_stemmed_sentences' for col in target_columns]].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a67e15d-be44-4afe-9779-46304068163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "target_columns = ['text_lemmatized_sentences', 'ingredient_lemmatized_sentences', 'name_lemmatized_sentences']\n",
    "\n",
    "with open(\"lemmatized_sentences_combined.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Başlık satırı (isteğe bağlı)\n",
    "    writer.writerow(target_columns)\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        row_data = []\n",
    "        for col in target_columns:\n",
    "            sentences = df.at[idx, col]  # Liste: cümle token listeleri\n",
    "            # Her cümleyi token listesinden stringe çevir ve '||' ile cümleleri ayır\n",
    "            sentences_str = ' || '.join([' '.join(tokens) for tokens in sentences])\n",
    "            row_data.append(sentences_str)\n",
    "        writer.writerow(row_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a80dbcb1-484d-44da-abff-6ef6a655f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "target_columns = ['text_stemmed_sentences', 'ingredient_stemmed_sentences', 'name_stemmed_sentences']\n",
    "\n",
    "with open(\"stemmed_sentences_combined.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Başlık satırı (isteğe bağlı)\n",
    "    writer.writerow(target_columns)\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        row_data = []\n",
    "        for col in target_columns:\n",
    "            sentences = df.at[idx, col]  # Liste: cümle token listeleri\n",
    "            # Her cümleyi token listesinden stringe çevir ve '||' ile cümleleri ayır\n",
    "            sentences_str = ' || '.join([' '.join(tokens) for tokens in sentences])\n",
    "            row_data.append(sentences_str)\n",
    "        writer.writerow(row_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136a810-f33e-445e-a704-caa3fe57bf16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
